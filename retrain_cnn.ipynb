{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np \n",
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from tensorflow.keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    " def retrain_model(x,y):\n",
    "    url=\"https://tfhub.dev/google/imagenet/inception_v3/feature_vector/5\"\n",
    "    base_model = hub.KerasLayer(url, input_shape=(200,200,3))\n",
    "\n",
    "    #base_model.trainable = False #Freezing layers\n",
    "    model = keras.Sequential([\n",
    "        base_model,\n",
    "        layers.Dense(128,activation='relu'),\n",
    "        layers.Dense(1, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        tf.keras.optimizers.Adam(),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']) \n",
    "    \n",
    "    model.fit(x,y, epochs=15, verbose=2)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_tensor(arg):\n",
    "  arg = tf.convert_to_tensor(arg, dtype=tf.float32)\n",
    "  return arg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../recognition/ids.csv', names=['image','class'], header=None)\n",
    "\n",
    "def read_images_labels(directory,traintest):\n",
    "    images=[]\n",
    "    labels=[]\n",
    "    for f in os.listdir(directory):                                 \n",
    "        img=cv2.imread(directory+\"/\"+f , cv2.IMREAD_COLOR)\n",
    "        img_resized = cv2.resize(img, (200, 200), interpolation = cv2.INTER_LINEAR)\n",
    "        images.append(img_resized)   \n",
    "        #print(img)\n",
    "        #cv2.imshow('image',img)\n",
    "        #cv2.waitKey(0)\n",
    "        labels.append(list(df[df.image==traintest+'/'+f]['class'])[0])\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train, images_train_labels =read_images_labels('../../dataset_cropped/train_cropped','train')\n",
    "images_test, images_test_labels=read_images_labels('../../dataset_cropped/test_cropped','test')        \n",
    "\n",
    "images_train=np.array(list(images_train))/255\n",
    "images_test=np.array(list(images_test))/255\n",
    "\n",
    "images_train_labels=np.asarray(images_train_labels)\n",
    "images_test_labels=np.asarray(images_test_labels)\n",
    "\n",
    "images_train = np.asarray(images_train)\n",
    "images_test = np.asarray(images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "24/24 - 22s - loss: 0.0000e+00 - accuracy: 0.0120 - 22s/epoch - 908ms/step\n",
      "Epoch 2/15\n",
      "24/24 - 18s - loss: 0.0000e+00 - accuracy: 0.0120 - 18s/epoch - 765ms/step\n",
      "Epoch 3/15\n",
      "24/24 - 19s - loss: 0.0000e+00 - accuracy: 0.0120 - 19s/epoch - 774ms/step\n",
      "Epoch 4/15\n",
      "24/24 - 20s - loss: 0.0000e+00 - accuracy: 0.0120 - 20s/epoch - 824ms/step\n",
      "Epoch 5/15\n",
      "24/24 - 42s - loss: 0.0000e+00 - accuracy: 0.0120 - 42s/epoch - 2s/step\n",
      "Epoch 6/15\n",
      "24/24 - 25s - loss: 0.0000e+00 - accuracy: 0.0120 - 25s/epoch - 1s/step\n",
      "Epoch 7/15\n",
      "24/24 - 21s - loss: 0.0000e+00 - accuracy: 0.0120 - 21s/epoch - 859ms/step\n",
      "Epoch 8/15\n",
      "24/24 - 19s - loss: 0.0000e+00 - accuracy: 0.0120 - 19s/epoch - 798ms/step\n",
      "Epoch 9/15\n",
      "24/24 - 19s - loss: 0.0000e+00 - accuracy: 0.0120 - 19s/epoch - 778ms/step\n",
      "Epoch 10/15\n",
      "24/24 - 21s - loss: 0.0000e+00 - accuracy: 0.0120 - 21s/epoch - 873ms/step\n",
      "Epoch 11/15\n",
      "24/24 - 21s - loss: 0.0000e+00 - accuracy: 0.0120 - 21s/epoch - 891ms/step\n",
      "Epoch 12/15\n",
      "24/24 - 22s - loss: 0.0000e+00 - accuracy: 0.0120 - 22s/epoch - 908ms/step\n",
      "Epoch 13/15\n",
      "24/24 - 21s - loss: 0.0000e+00 - accuracy: 0.0120 - 21s/epoch - 895ms/step\n",
      "Epoch 14/15\n",
      "24/24 - 22s - loss: 0.0000e+00 - accuracy: 0.0120 - 22s/epoch - 911ms/step\n",
      "Epoch 15/15\n",
      "24/24 - 24s - loss: 0.0000e+00 - accuracy: 0.0120 - 24s/epoch - 1s/step\n"
     ]
    }
   ],
   "source": [
    "model=retrain_model(images_train, images_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=(model.predict(images_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 200, 200, 3)\n",
      "(750, 101)\n"
     ]
    }
   ],
   "source": [
    "print(images_train.shape)\n",
    "print(y_train.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
