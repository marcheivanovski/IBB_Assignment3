{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try overlapping and smaller regions\n",
    "def extract_feature_vector(img):\n",
    "    splits=[0,50,100,150,200]\n",
    "    blocks=[]\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            blocks.append(list(img[splits[i]:splits[i+1], splits[j]:splits[j+1]]))\n",
    "    \n",
    "   \n",
    "    histograms=[{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{}]\n",
    "    for i in range(256):\n",
    "        for j in range(16):\n",
    "            histograms[j][i]=0\n",
    "    \n",
    "    count=0\n",
    "    for i in blocks:\n",
    "        for m in i:\n",
    "            for n in m:\n",
    "                histograms[count][n]+=1\n",
    "                \n",
    "        count+=1\n",
    "    \n",
    "    feature_vector=[]\n",
    "    \n",
    "    for i in histograms:\n",
    "        feature_vector=feature_vector+list(i.values())\n",
    "        \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My own coded LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.listdir('../../dataset_lbp/train')\n",
    "df=pd.read_csv('../recognition/ids.csv', names=['image','class'], header=None)\n",
    "\n",
    "X_train=[]\n",
    "Y_train=[]\n",
    "\n",
    "for file in directory:\n",
    "    img = cv2.imread(\"../../dataset_lbp/train/\" + file, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    img_resized = cv2.resize(img, (200, 200), interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    feature_vector=extract_feature_vector(img_resized)\n",
    "    \n",
    "    X_train.append(feature_vector)\n",
    "    Y_train.append( list(df[df.image=='train/'+file]['class'])[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.listdir('../../dataset_lbp/test')\n",
    "df=pd.read_csv('../recognition/ids.csv', names=['image','class'], header=None)\n",
    "\n",
    "X_test=[]\n",
    "Y_test=[]\n",
    "\n",
    "for file in directory:\n",
    "    img = cv2.imread(\"../../dataset_lbp/test/\" + file, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    img_resized = cv2.resize(img, (200, 200), interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "    feature_vector=extract_feature_vector(img_resized)\n",
    "            \n",
    "    X_test.append(feature_vector)\n",
    "    Y_test.append( list(df[df.image=='train/'+file]['class'])[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.004016064257028112\n"
     ]
    }
   ],
   "source": [
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_pred=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marko\\anaconda3\\envs\\ids-clone\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:54:28] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.01606425702811245\n"
     ]
    }
   ],
   "source": [
    "xg_model = xgb.XGBClassifier()\n",
    "xg_model.fit(X_train, Y_train)\n",
    "Y_predicted = xg_model.predict(X_test)\n",
    "#print(classification_report(Y_test, Y_predicted))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn LBP\n",
    "- https://scikit-image.org/docs/stable/api/skimage.feature.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import local_binary_pattern, hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.listdir('../../dataset_cropped/train_cropped')\n",
    "#print(directory)\n",
    "\n",
    "X_train=[]\n",
    "Y_train=[]\n",
    "for file in directory:\n",
    "    img = cv2.imread(\"../../dataset_cropped/train_cropped/\" + file, cv2.IMREAD_COLOR)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "       \n",
    "    lbp = local_binary_pattern(img_gray, 8, 1, 'uniform')\n",
    "    \n",
    "    lbp = cv2.resize(lbp, (200, 200), interpolation = cv2.INTER_LINEAR)\n",
    "    feature_vector=extract_feature_vector(lbp)\n",
    "    \n",
    "    X_train.append(feature_vector)\n",
    "    Y_train.append( list(df[df.image=='train/'+file]['class'])[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = os.listdir('../../dataset_cropped/test_cropped')\n",
    "#print(directory)\n",
    "\n",
    "X_test=[]\n",
    "Y_test=[]\n",
    "for file in directory:\n",
    "    img = cv2.imread(\"../../dataset_cropped/test_cropped/\" + file, cv2.IMREAD_COLOR)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "   \n",
    "    lbp = local_binary_pattern(img_gray, 8, 1, 'uniform')\n",
    "    lbp = cv2.resize(lbp, (200, 200), interpolation = cv2.INTER_LINEAR)\n",
    "    feature_vector=extract_feature_vector(lbp)\n",
    "    \n",
    "    X_test.append(feature_vector)\n",
    "    Y_test.append( list(df[df.image=='train/'+file]['class'])[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 4096)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,Y_train)\n",
    "Y_pred=clf.predict(X_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marko\\anaconda3\\envs\\ids-clone\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:03:30] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "xg_model = xgb.XGBClassifier()\n",
    "xg_model.fit(X_train, Y_train)\n",
    "Y_predicted = xg_model.predict(X_test)\n",
    "#print(classification_report(Y_test, Y_predicted))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ids-clone]",
   "language": "python",
   "name": "conda-env-ids-clone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
